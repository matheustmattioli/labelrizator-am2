{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions \n",
    "\n",
    "Esse Jupyter Notebook apresenta nosso estudo e os resultados obtidos para o conjunto de dados *Emotions*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação dos pacotes\n",
    "# !pip install --upgrade pip\n",
    "# !pip install scikit-multilearn\n",
    "# !pip install scipy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados e Pré-processamento\n",
    "\n",
    "A função convert é responsável por transformar dados categóricos e binários para dados numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(a):\n",
    "    # tenta converter para uma string\n",
    "    try:\n",
    "        b = a.decode(\"utf-8\")\n",
    "    except:\n",
    "        # eh um numero\n",
    "        return a\n",
    "    # tenta converter para um inteiro\n",
    "    try:\n",
    "        return int(b)\n",
    "    except:\n",
    "        # eh um atributo nominal\n",
    "        if b == 'YES':\n",
    "            return 1\n",
    "        if b == 'NO':\n",
    "            return 0\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Mean_Acc1298_Mean_Mem40_Centroid  Mean_Acc1298_Mean_Mem40_Rolloff  \\\n",
      "0                            0.036299                         0.064986   \n",
      "1                            0.161218                         0.467820   \n",
      "2                            0.115987                         0.336879   \n",
      "3                            0.086016                         0.141845   \n",
      "4                            0.063232                         0.140621   \n",
      "..                                ...                              ...   \n",
      "197                          0.027142                         0.047551   \n",
      "198                          0.094829                         0.204498   \n",
      "199                          0.035169                         0.065403   \n",
      "200                          0.054276                         0.238158   \n",
      "201                          0.073194                         0.140733   \n",
      "\n",
      "     Mean_Acc1298_Mean_Mem40_Flux  Mean_Acc1298_Mean_Mem40_MFCC_0  \\\n",
      "0                        0.082104                      -72.710462   \n",
      "1                        0.096983                      -71.298043   \n",
      "2                        0.079068                      -64.570939   \n",
      "3                        0.081554                      -81.141092   \n",
      "4                        0.082097                      -66.596131   \n",
      "..                            ...                             ...   \n",
      "197                      0.072043                      -79.881347   \n",
      "198                      0.082824                      -61.364436   \n",
      "199                      0.075227                      -81.750533   \n",
      "200                      0.095935                      -71.009724   \n",
      "201                      0.080545                      -74.517081   \n",
      "\n",
      "     Mean_Acc1298_Mean_Mem40_MFCC_1  Mean_Acc1298_Mean_Mem40_MFCC_2  \\\n",
      "0                          7.920220                        0.134279   \n",
      "1                          1.176349                        1.871744   \n",
      "2                          2.339044                        0.714859   \n",
      "3                          6.714252                       -1.338896   \n",
      "4                          5.594724                        0.350716   \n",
      "..                              ...                             ...   \n",
      "197                        8.119313                        1.927310   \n",
      "198                        2.966229                        0.627740   \n",
      "199                       10.311701                        0.092224   \n",
      "200                        3.181340                        1.547197   \n",
      "201                        6.945590                       -1.047953   \n",
      "\n",
      "     Mean_Acc1298_Mean_Mem40_MFCC_3  Mean_Acc1298_Mean_Mem40_MFCC_4  \\\n",
      "0                          2.546373                        0.671063   \n",
      "1                          1.097346                        0.641059   \n",
      "2                          1.792451                        0.611347   \n",
      "3                          1.326248                        0.340032   \n",
      "4                          1.023655                        0.439544   \n",
      "..                              ...                             ...   \n",
      "197                        1.696017                        0.397888   \n",
      "198                        1.440352                        0.856243   \n",
      "199                        0.818851                        1.569606   \n",
      "200                        2.407780                        0.618838   \n",
      "201                        1.952278                        0.341936   \n",
      "\n",
      "     Mean_Acc1298_Mean_Mem40_MFCC_5  Mean_Acc1298_Mean_Mem40_MFCC_6  ...  \\\n",
      "0                          1.589821                        0.576485  ...   \n",
      "1                          0.372797                        0.991050  ...   \n",
      "2                          0.287022                        0.772846  ...   \n",
      "3                          1.290664                        0.337209  ...   \n",
      "4                          0.855564                        0.414784  ...   \n",
      "..                              ...                             ...  ...   \n",
      "197                        0.857559                        0.302742  ...   \n",
      "198                        1.110282                        0.394450  ...   \n",
      "199                        1.831909                        0.057216  ...   \n",
      "200                        0.997950                        0.825143  ...   \n",
      "201                        0.770582                        0.144989  ...   \n",
      "\n",
      "     BH_HighLowRatio    BHSUM1    BHSUM2    BHSUM3  amazed-suprised  \\\n",
      "0                2.0  0.095982  0.520006  0.677943             b'0'   \n",
      "1                2.0  0.752210  0.576382  1.477141             b'1'   \n",
      "2                2.0  0.488375  0.004603  1.147727             b'0'   \n",
      "3                2.0  0.430059  0.102757  1.276632             b'0'   \n",
      "4                2.0  1.788567  0.032760  3.076057             b'0'   \n",
      "..               ...       ...       ...       ...              ...   \n",
      "197              2.0  0.261742  0.002657  1.149211             b'0'   \n",
      "198              2.0  0.282122  0.052218  0.335371             b'1'   \n",
      "199              2.0  0.184313  0.247136  0.476993             b'0'   \n",
      "200              2.0  0.547126  0.183494  1.255820             b'0'   \n",
      "201              2.0  0.087328  0.236815  0.451701             b'0'   \n",
      "\n",
      "     happy-pleased  relaxing-calm  quiet-still  sad-lonely  angry-aggresive  \n",
      "0             b'0'           b'1'         b'1'        b'1'             b'0'  \n",
      "1             b'0'           b'0'         b'0'        b'0'             b'1'  \n",
      "2             b'0'           b'0'         b'0'        b'1'             b'0'  \n",
      "3             b'1'           b'1'         b'0'        b'0'             b'0'  \n",
      "4             b'0'           b'0'         b'0'        b'1'             b'0'  \n",
      "..             ...            ...          ...         ...              ...  \n",
      "197           b'0'           b'1'         b'1'        b'1'             b'0'  \n",
      "198           b'0'           b'0'         b'0'        b'1'             b'1'  \n",
      "199           b'0'           b'1'         b'1'        b'1'             b'0'  \n",
      "200           b'1'           b'1'         b'0'        b'0'             b'0'  \n",
      "201           b'1'           b'0'         b'0'        b'0'             b'0'  \n",
      "\n",
      "[202 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Imports necessários para extraçao dos dados\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando o treino\n",
    "data_train, meta_train = scipy.io.arff.loadarff(f'datasets/emotions/emotions-train.arff')\n",
    "X_train = pd.DataFrame(data_train)\n",
    "\n",
    "# Carregando o teste\n",
    "data_test, meta_test = scipy.io.arff.loadarff(f'datasets/emotions/emotions-test.arff')\n",
    "X_test = pd.DataFrame(data_test)\n",
    "\n",
    "# Pré-processamento\n",
    "# Transformando em atributos numéricos\n",
    "X_test = X_test.applymap(convert)\n",
    "X_train = X_train.applymap(convert)\n",
    "\n",
    "\n",
    "\n",
    "# # Separando o Y do treino\n",
    "Y_train = X_train.iloc[:, -72:]\n",
    "X_train.drop(columns=list(Y_train.columns), inplace=True)\n",
    "\n",
    "# # Separando o Y do teste\n",
    "Y_test = X_test.iloc[:, -72:]\n",
    "X_test.drop(columns=list(Y_test.columns), inplace=True)\n",
    "\n",
    "\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_3</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_4</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_5</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_6</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_7</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_8</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_9</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_10</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_11</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_12</th>\n",
       "      <th>...</th>\n",
       "      <th>BH_HighLowRatio</th>\n",
       "      <th>BHSUM1</th>\n",
       "      <th>BHSUM2</th>\n",
       "      <th>BHSUM3</th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-calm</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.546373</td>\n",
       "      <td>0.671063</td>\n",
       "      <td>1.589821</td>\n",
       "      <td>0.576485</td>\n",
       "      <td>0.089158</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.167199</td>\n",
       "      <td>0.661612</td>\n",
       "      <td>0.139440</td>\n",
       "      <td>0.453410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.095982</td>\n",
       "      <td>0.520006</td>\n",
       "      <td>0.677943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.097346</td>\n",
       "      <td>0.641059</td>\n",
       "      <td>0.372797</td>\n",
       "      <td>0.991050</td>\n",
       "      <td>0.398497</td>\n",
       "      <td>0.620176</td>\n",
       "      <td>0.640384</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>0.771620</td>\n",
       "      <td>0.377546</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.752210</td>\n",
       "      <td>0.576382</td>\n",
       "      <td>1.477141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.792451</td>\n",
       "      <td>0.611347</td>\n",
       "      <td>0.287022</td>\n",
       "      <td>0.772846</td>\n",
       "      <td>0.858681</td>\n",
       "      <td>0.516220</td>\n",
       "      <td>0.953049</td>\n",
       "      <td>0.462743</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.692991</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.488375</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>1.147727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.326248</td>\n",
       "      <td>0.340032</td>\n",
       "      <td>1.290664</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>0.419102</td>\n",
       "      <td>0.817250</td>\n",
       "      <td>0.485674</td>\n",
       "      <td>0.346063</td>\n",
       "      <td>0.314718</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.430059</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>1.276632</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.023655</td>\n",
       "      <td>0.439544</td>\n",
       "      <td>0.855564</td>\n",
       "      <td>0.414784</td>\n",
       "      <td>0.086249</td>\n",
       "      <td>0.316512</td>\n",
       "      <td>0.758706</td>\n",
       "      <td>0.556832</td>\n",
       "      <td>0.436872</td>\n",
       "      <td>0.649256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.788567</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>3.076057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.696017</td>\n",
       "      <td>0.397888</td>\n",
       "      <td>0.857559</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>0.672649</td>\n",
       "      <td>0.748163</td>\n",
       "      <td>0.412952</td>\n",
       "      <td>0.852625</td>\n",
       "      <td>0.597127</td>\n",
       "      <td>0.456126</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.261742</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>1.149211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.440352</td>\n",
       "      <td>0.856243</td>\n",
       "      <td>1.110282</td>\n",
       "      <td>0.394450</td>\n",
       "      <td>0.726323</td>\n",
       "      <td>0.885339</td>\n",
       "      <td>0.517613</td>\n",
       "      <td>-0.186371</td>\n",
       "      <td>0.531083</td>\n",
       "      <td>0.312116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.282122</td>\n",
       "      <td>0.052218</td>\n",
       "      <td>0.335371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.818851</td>\n",
       "      <td>1.569606</td>\n",
       "      <td>1.831909</td>\n",
       "      <td>0.057216</td>\n",
       "      <td>0.419342</td>\n",
       "      <td>0.482342</td>\n",
       "      <td>0.745151</td>\n",
       "      <td>0.403275</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>0.711755</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.184313</td>\n",
       "      <td>0.247136</td>\n",
       "      <td>0.476993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.407780</td>\n",
       "      <td>0.618838</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.825143</td>\n",
       "      <td>0.758816</td>\n",
       "      <td>0.727540</td>\n",
       "      <td>0.500074</td>\n",
       "      <td>0.402084</td>\n",
       "      <td>0.539242</td>\n",
       "      <td>0.326410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.547126</td>\n",
       "      <td>0.183494</td>\n",
       "      <td>1.255820</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.952278</td>\n",
       "      <td>0.341936</td>\n",
       "      <td>0.770582</td>\n",
       "      <td>0.144989</td>\n",
       "      <td>0.405832</td>\n",
       "      <td>0.186847</td>\n",
       "      <td>0.496161</td>\n",
       "      <td>0.389096</td>\n",
       "      <td>0.324653</td>\n",
       "      <td>0.193508</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.087328</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>0.451701</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean_Acc1298_Mean_Mem40_MFCC_3  Mean_Acc1298_Mean_Mem40_MFCC_4  \\\n",
       "0                          2.546373                        0.671063   \n",
       "1                          1.097346                        0.641059   \n",
       "2                          1.792451                        0.611347   \n",
       "3                          1.326248                        0.340032   \n",
       "4                          1.023655                        0.439544   \n",
       "..                              ...                             ...   \n",
       "197                        1.696017                        0.397888   \n",
       "198                        1.440352                        0.856243   \n",
       "199                        0.818851                        1.569606   \n",
       "200                        2.407780                        0.618838   \n",
       "201                        1.952278                        0.341936   \n",
       "\n",
       "     Mean_Acc1298_Mean_Mem40_MFCC_5  Mean_Acc1298_Mean_Mem40_MFCC_6  \\\n",
       "0                          1.589821                        0.576485   \n",
       "1                          0.372797                        0.991050   \n",
       "2                          0.287022                        0.772846   \n",
       "3                          1.290664                        0.337209   \n",
       "4                          0.855564                        0.414784   \n",
       "..                              ...                             ...   \n",
       "197                        0.857559                        0.302742   \n",
       "198                        1.110282                        0.394450   \n",
       "199                        1.831909                        0.057216   \n",
       "200                        0.997950                        0.825143   \n",
       "201                        0.770582                        0.144989   \n",
       "\n",
       "     Mean_Acc1298_Mean_Mem40_MFCC_7  Mean_Acc1298_Mean_Mem40_MFCC_8  \\\n",
       "0                          0.089158                        0.261224   \n",
       "1                          0.398497                        0.620176   \n",
       "2                          0.858681                        0.516220   \n",
       "3                          0.156768                        0.419102   \n",
       "4                          0.086249                        0.316512   \n",
       "..                              ...                             ...   \n",
       "197                        0.672649                        0.748163   \n",
       "198                        0.726323                        0.885339   \n",
       "199                        0.419342                        0.482342   \n",
       "200                        0.758816                        0.727540   \n",
       "201                        0.405832                        0.186847   \n",
       "\n",
       "     Mean_Acc1298_Mean_Mem40_MFCC_9  Mean_Acc1298_Mean_Mem40_MFCC_10  \\\n",
       "0                          0.167199                         0.661612   \n",
       "1                          0.640384                         0.371496   \n",
       "2                          0.953049                         0.462743   \n",
       "3                          0.817250                         0.485674   \n",
       "4                          0.758706                         0.556832   \n",
       "..                              ...                              ...   \n",
       "197                        0.412952                         0.852625   \n",
       "198                        0.517613                        -0.186371   \n",
       "199                        0.745151                         0.403275   \n",
       "200                        0.500074                         0.402084   \n",
       "201                        0.496161                         0.389096   \n",
       "\n",
       "     Mean_Acc1298_Mean_Mem40_MFCC_11  Mean_Acc1298_Mean_Mem40_MFCC_12  ...  \\\n",
       "0                           0.139440                         0.453410  ...   \n",
       "1                           0.771620                         0.377546  ...   \n",
       "2                           0.278748                         0.692991  ...   \n",
       "3                           0.346063                         0.314718  ...   \n",
       "4                           0.436872                         0.649256  ...   \n",
       "..                               ...                              ...  ...   \n",
       "197                         0.597127                         0.456126  ...   \n",
       "198                         0.531083                         0.312116  ...   \n",
       "199                         0.838195                         0.711755  ...   \n",
       "200                         0.539242                         0.326410  ...   \n",
       "201                         0.324653                         0.193508  ...   \n",
       "\n",
       "     BH_HighLowRatio    BHSUM1    BHSUM2    BHSUM3  amazed-suprised  \\\n",
       "0                2.0  0.095982  0.520006  0.677943                0   \n",
       "1                2.0  0.752210  0.576382  1.477141                1   \n",
       "2                2.0  0.488375  0.004603  1.147727                0   \n",
       "3                2.0  0.430059  0.102757  1.276632                0   \n",
       "4                2.0  1.788567  0.032760  3.076057                0   \n",
       "..               ...       ...       ...       ...              ...   \n",
       "197              2.0  0.261742  0.002657  1.149211                0   \n",
       "198              2.0  0.282122  0.052218  0.335371                1   \n",
       "199              2.0  0.184313  0.247136  0.476993                0   \n",
       "200              2.0  0.547126  0.183494  1.255820                0   \n",
       "201              2.0  0.087328  0.236815  0.451701                0   \n",
       "\n",
       "     happy-pleased  relaxing-calm  quiet-still  sad-lonely  angry-aggresive  \n",
       "0                0              1            1           1                0  \n",
       "1                0              0            0           0                1  \n",
       "2                0              0            0           1                0  \n",
       "3                1              1            0           0                0  \n",
       "4                0              0            0           1                0  \n",
       "..             ...            ...          ...         ...              ...  \n",
       "197              0              1            1           1                0  \n",
       "198              0              0            0           1                1  \n",
       "199              0              1            1           1                0  \n",
       "200              1              1            0           0                0  \n",
       "201              1              0            0           0                0  \n",
       "\n",
       "[202 rows x 72 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se o pré-processamento foi bem sucedida nos rótulos.\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos\n",
    "Vamos estudar esse conjunto de dados com três métodos de classificação multirrótulo:\n",
    "- Binary Relevance\n",
    "- Classifier Chains\n",
    "- Label Powersets.\n",
    "\n",
    "Também utilizamos três classificadores de um rótulo para cada classificador multirrótulo, são eles:\n",
    "- Multinomial Naive Bayes\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 667, in fit\n",
      "    Y = labelbin.fit_transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 324, in fit_transform\n",
      "    return self.fit(y).transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 301, in fit\n",
      "    self.classes_ = unique_labels(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 101, in unique_labels\n",
      "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
      "ValueError: Unknown label type: (array([ 0.97536 ,  1.454806,  1.275982,  2.43297 ,  1.496289,  1.919519,\n",
      "        1.625344,  1.940156,  1.636232,  1.572476,  1.034744,  0.32983 ,\n",
      "        0.850997,  2.136364,  1.418559,  1.908576,  0.659024,  0.943949,\n",
      "        1.812999,  2.163561,  0.63267 ,  2.024609,  1.018783,  0.989734,\n",
      "        1.850331,  0.684279,  2.312619,  0.827751,  0.538632,  1.052897,\n",
      "        0.289061,  1.523284,  0.600617,  1.595451,  2.337256,  2.43986 ,\n",
      "        2.646499,  1.327861,  1.304352,  1.981126,  1.126918,  2.477158,\n",
      "        2.497154,  1.227564,  1.019767,  1.807693,  1.993607,  0.693808,\n",
      "        2.120061,  1.388073,  1.300283,  1.773946,  0.735255,  1.396992,\n",
      "        2.039208,  0.545693,  2.601184,  0.917574,  1.927231,  1.526764,\n",
      "        1.750901,  2.175883,  1.439402,  2.946012,  0.334413,  2.006773,\n",
      "        1.002989,  2.036271,  1.658998,  1.477642,  1.638622,  1.229398,\n",
      "        1.123619,  2.073003,  1.205349,  0.615066,  2.350868,  2.729505,\n",
      "        1.591389,  0.538881,  1.933134,  1.800501,  2.174924,  1.994149,\n",
      "        1.732324,  1.22614 ,  0.689976,  0.938858,  1.717564,  0.932902,\n",
      "        0.289973,  0.914739,  1.404664,  3.196087,  1.536225,  0.597421,\n",
      "        1.623288,  1.34925 ,  0.889211, -0.443957,  1.640724,  2.152459,\n",
      "        1.066205,  2.073372,  1.251505, -0.154632,  2.009931,  1.379951,\n",
      "        1.487149,  3.171676,  1.307823,  1.317858,  1.850503,  1.243308,\n",
      "        1.207273,  0.427459,  1.901207,  1.328667,  1.252132,  2.28458 ,\n",
      "        1.278584,  2.551586,  0.738186,  2.09616 ,  1.341293,  2.459356,\n",
      "        1.799596,  1.751104,  1.81114 ,  1.784472,  2.119735,  2.421237,\n",
      "        1.608835,  0.306131,  0.576   ,  1.494694,  2.116776,  2.273904,\n",
      "        2.712332,  1.076953,  0.589   ,  2.383639, -0.604609,  1.990152,\n",
      "        1.521183,  1.829104,  1.828428,  1.934537,  1.823401,  1.80986 ,\n",
      "        0.406858,  1.393505,  1.45706 ,  0.521478,  0.630303,  0.561558,\n",
      "        0.874383,  2.320437,  2.389362,  2.171778,  2.449553,  1.301573,\n",
      "        1.873835,  2.232851,  2.598119,  0.532722,  2.133964,  0.882511,\n",
      "        1.759203,  2.507832,  4.38237 ,  1.591212,  1.759308,  2.062261,\n",
      "        1.044671,  1.268465,  1.845302,  1.731031,  2.162984,  2.457407,\n",
      "        1.21513 ,  1.635316,  1.799942,  1.497437,  1.608918,  1.644011,\n",
      "        1.75933 ,  1.878956,  2.078355,  2.660737,  1.822076,  1.963631,\n",
      "        1.733528,  2.182249,  1.754007,  1.59271 ,  2.347214,  1.950402,\n",
      "        2.338371,  1.659106,  1.636299,  1.950205,  1.695195,  1.288635,\n",
      "        1.947221,  2.243745,  2.075306,  1.663446,  1.227539,  0.8751  ,\n",
      "        1.61698 ,  2.495399,  2.369219,  1.510265,  2.360308,  1.672772,\n",
      "        1.485888,  1.282133,  1.147457,  1.11794 ,  1.485829,  2.572892,\n",
      "        2.837846,  1.516674,  1.381426,  2.494787,  2.017904,  1.793095,\n",
      "        2.749407,  2.712948,  1.551902,  1.79027 ,  1.80543 ,  2.419999,\n",
      "        2.078648,  2.237646,  2.073871,  1.697372,  2.085312,  1.431316,\n",
      "        1.855865,  1.838725,  1.502847,  1.386911,  2.539702,  2.250318,\n",
      "        2.699614,  1.962541,  1.462936,  2.243822,  0.535551,  2.052821,\n",
      "        1.904891,  1.924109,  2.584028,  1.376695,  0.789463,  2.560538,\n",
      "        1.778239,  1.801168,  0.952802,  1.117003,  1.781188,  1.002689,\n",
      "        2.00098 ,  1.041688,  2.665764,  1.945364,  1.252723,  1.70798 ,\n",
      "        2.125263,  2.1003  ,  2.409154,  2.374433,  1.071791,  1.385475,\n",
      "        2.445202,  1.550953,  1.960151,  2.620628,  1.713357,  1.022162,\n",
      "        1.067337,  1.698138,  2.001137,  1.672983,  0.900969,  1.65972 ,\n",
      "        1.392194,  1.301803,  1.666855,  3.468003,  0.820257,  1.66819 ,\n",
      "        1.130072,  1.943092,  1.915641,  1.774768,  2.067105,  1.067635,\n",
      "        1.506847,  2.118687,  1.432958,  1.746974,  2.234938,  1.017468,\n",
      "        1.880618,  1.224303,  1.340068,  2.667867,  2.507652,  1.507785]),)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 667, in fit\n",
      "    Y = labelbin.fit_transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 324, in fit_transform\n",
      "    return self.fit(y).transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 301, in fit\n",
      "    self.classes_ = unique_labels(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 101, in unique_labels\n",
      "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
      "ValueError: Unknown label type: (array([ 2.03716 ,  0.163038,  1.281297,  1.75487 ,  0.899152,  2.873985,\n",
      "        2.063466,  1.641708,  1.681155,  1.008498,  2.00859 ,  2.069593,\n",
      "        1.257558,  2.403569,  2.065888,  1.697092,  2.066208,  2.334506,\n",
      "        1.878594,  1.918101,  1.32222 ,  2.185029,  2.358581,  1.941173,\n",
      "        1.363718,  2.300394,  2.166609,  0.760122,  1.11421 ,  1.185565,\n",
      "        1.82109 ,  0.97603 ,  1.033672,  1.776699,  1.52138 ,  1.569112,\n",
      "        2.349911,  2.37475 ,  1.259821,  1.534706,  1.118819,  1.561411,\n",
      "        1.9349  ,  1.5788  ,  0.980418,  2.329825,  1.825435,  2.916244,\n",
      "        2.049976,  1.670072,  1.117681,  1.515848,  1.576656,  1.913779,\n",
      "        0.90638 ,  2.261804,  1.926829,  2.703565,  0.191738,  1.369578,\n",
      "        1.946866,  0.493437,  1.309338,  1.521604,  2.529736,  2.435505,\n",
      "        2.112233,  1.706145,  2.240627,  1.635215,  1.970481,  2.61666 ,\n",
      "        1.3327  ,  1.497519,  2.046647,  2.227846,  1.835204,  1.500811,\n",
      "        1.958153,  1.591389,  0.538881,  1.933134,  1.800501,  2.174924,\n",
      "        1.994149,  1.732324,  1.22614 ,  0.689976,  0.938858,  1.717564,\n",
      "        0.932902,  0.289973,  0.914739,  1.404664,  3.196087,  1.536225,\n",
      "        0.597421,  1.623288,  1.34925 ,  0.889211, -0.443957,  1.640724,\n",
      "        2.152459,  1.066205,  2.073372,  1.251505, -0.154632,  2.009931,\n",
      "        1.379951,  1.487149,  3.171676,  1.307823,  1.317858,  1.850503,\n",
      "        1.243308,  1.207273,  0.427459,  1.901207,  1.328667,  1.252132,\n",
      "        2.28458 ,  1.278584,  2.551586,  0.738186,  2.09616 ,  1.341293,\n",
      "        2.459356,  1.799596,  1.751104,  1.81114 ,  1.784472,  2.119735,\n",
      "        2.421237,  1.608835,  0.306131,  0.576   ,  1.494694,  2.116776,\n",
      "        2.273904,  2.712332,  1.076953,  0.589   ,  2.383639, -0.604609,\n",
      "        1.990152,  1.521183,  1.829104,  1.828428,  1.934537,  1.823401,\n",
      "        1.80986 ,  0.406858,  1.393505,  1.45706 ,  0.521478,  0.630303,\n",
      "        0.561558,  0.874383,  2.320437,  2.389362,  2.171778,  2.449553,\n",
      "        1.301573,  1.873835,  2.232851,  2.598119,  0.532722,  2.133964,\n",
      "        0.882511,  1.759203,  2.507832,  4.38237 ,  1.591212,  1.759308,\n",
      "        2.062261,  1.044671,  1.268465,  1.845302,  1.731031,  2.162984,\n",
      "        2.457407,  1.21513 ,  1.635316,  1.799942,  1.497437,  1.608918,\n",
      "        1.644011,  1.75933 ,  1.878956,  2.078355,  2.660737,  1.822076,\n",
      "        1.963631,  1.733528,  2.182249,  1.754007,  1.59271 ,  2.347214,\n",
      "        1.950402,  2.338371,  1.659106,  1.636299,  1.950205,  1.695195,\n",
      "        1.288635,  1.947221,  2.243745,  2.075306,  1.663446,  1.227539,\n",
      "        0.8751  ,  1.61698 ,  2.495399,  2.369219,  1.510265,  2.360308,\n",
      "        1.672772,  1.485888,  1.282133,  1.147457,  1.11794 ,  1.485829,\n",
      "        2.572892,  2.837846,  1.516674,  1.381426,  2.494787,  2.017904,\n",
      "        1.793095,  2.749407,  2.712948,  1.551902,  1.79027 ,  1.80543 ,\n",
      "        2.419999,  2.078648,  2.237646,  2.073871,  1.697372,  2.085312,\n",
      "        1.431316,  1.855865,  1.838725,  1.502847,  1.386911,  2.539702,\n",
      "        2.250318,  2.699614,  1.962541,  1.462936,  2.243822,  0.535551,\n",
      "        2.052821,  1.904891,  1.924109,  2.584028,  1.376695,  0.789463,\n",
      "        2.560538,  1.778239,  1.801168,  0.952802,  1.117003,  1.781188,\n",
      "        1.002689,  2.00098 ,  1.041688,  2.665764,  1.945364,  1.252723,\n",
      "        1.70798 ,  2.125263,  2.1003  ,  2.409154,  2.374433,  1.071791,\n",
      "        1.385475,  2.445202,  1.550953,  1.960151,  2.620628,  1.713357,\n",
      "        1.022162,  1.067337,  1.698138,  2.001137,  1.672983,  0.900969,\n",
      "        1.65972 ,  1.392194,  1.301803,  1.666855,  3.468003,  0.820257,\n",
      "        1.66819 ,  1.130072,  1.943092,  1.915641,  1.774768,  2.067105,\n",
      "        1.067635,  1.506847,  2.118687,  1.432958,  1.746974,  2.234938,\n",
      "        1.017468,  1.880618,  1.224303,  1.340068,  2.667867,  2.507652,\n",
      "        1.507785]),)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 667, in fit\n",
      "    Y = labelbin.fit_transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 324, in fit_transform\n",
      "    return self.fit(y).transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 301, in fit\n",
      "    self.classes_ = unique_labels(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 101, in unique_labels\n",
      "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
      "ValueError: Unknown label type: (array([2.03716 , 0.163038, 1.281297, 1.75487 , 0.899152, 2.873985,\n",
      "       2.063466, 1.641708, 1.681155, 1.008498, 2.00859 , 2.069593,\n",
      "       1.257558, 2.403569, 2.065888, 1.697092, 2.066208, 2.334506,\n",
      "       1.878594, 1.918101, 1.32222 , 2.185029, 2.358581, 1.941173,\n",
      "       1.363718, 2.300394, 2.166609, 0.760122, 1.11421 , 1.185565,\n",
      "       1.82109 , 0.97603 , 1.033672, 1.776699, 1.52138 , 1.569112,\n",
      "       2.349911, 2.37475 , 1.259821, 1.534706, 1.118819, 1.561411,\n",
      "       1.9349  , 1.5788  , 0.980418, 2.329825, 1.825435, 2.916244,\n",
      "       2.049976, 1.670072, 1.117681, 1.515848, 1.576656, 1.913779,\n",
      "       0.90638 , 2.261804, 1.926829, 2.703565, 0.191738, 1.369578,\n",
      "       1.946866, 0.493437, 1.309338, 1.521604, 2.529736, 2.435505,\n",
      "       2.112233, 1.706145, 2.240627, 1.635215, 1.970481, 2.61666 ,\n",
      "       1.3327  , 1.497519, 2.046647, 2.227846, 1.835204, 1.500811,\n",
      "       1.958153, 0.97536 , 1.454806, 1.275982, 2.43297 , 1.496289,\n",
      "       1.919519, 1.625344, 1.940156, 1.636232, 1.572476, 1.034744,\n",
      "       0.32983 , 0.850997, 2.136364, 1.418559, 1.908576, 0.659024,\n",
      "       0.943949, 1.812999, 2.163561, 0.63267 , 2.024609, 1.018783,\n",
      "       0.989734, 1.850331, 0.684279, 2.312619, 0.827751, 0.538632,\n",
      "       1.052897, 0.289061, 1.523284, 0.600617, 1.595451, 2.337256,\n",
      "       2.43986 , 2.646499, 1.327861, 1.304352, 1.981126, 1.126918,\n",
      "       2.477158, 2.497154, 1.227564, 1.019767, 1.807693, 1.993607,\n",
      "       0.693808, 2.120061, 1.388073, 1.300283, 1.773946, 0.735255,\n",
      "       1.396992, 2.039208, 0.545693, 2.601184, 0.917574, 1.927231,\n",
      "       1.526764, 1.750901, 2.175883, 1.439402, 2.946012, 0.334413,\n",
      "       2.006773, 1.002989, 2.036271, 1.658998, 1.477642, 1.638622,\n",
      "       1.229398, 1.123619, 2.073003, 1.205349, 0.615066, 2.350868,\n",
      "       2.729505, 0.874383, 2.320437, 2.389362, 2.171778, 2.449553,\n",
      "       1.301573, 1.873835, 2.232851, 2.598119, 0.532722, 2.133964,\n",
      "       0.882511, 1.759203, 2.507832, 4.38237 , 1.591212, 1.759308,\n",
      "       2.062261, 1.044671, 1.268465, 1.845302, 1.731031, 2.162984,\n",
      "       2.457407, 1.21513 , 1.635316, 1.799942, 1.497437, 1.608918,\n",
      "       1.644011, 1.75933 , 1.878956, 2.078355, 2.660737, 1.822076,\n",
      "       1.963631, 1.733528, 2.182249, 1.754007, 1.59271 , 2.347214,\n",
      "       1.950402, 2.338371, 1.659106, 1.636299, 1.950205, 1.695195,\n",
      "       1.288635, 1.947221, 2.243745, 2.075306, 1.663446, 1.227539,\n",
      "       0.8751  , 1.61698 , 2.495399, 2.369219, 1.510265, 2.360308,\n",
      "       1.672772, 1.485888, 1.282133, 1.147457, 1.11794 , 1.485829,\n",
      "       2.572892, 2.837846, 1.516674, 1.381426, 2.494787, 2.017904,\n",
      "       1.793095, 2.749407, 2.712948, 1.551902, 1.79027 , 1.80543 ,\n",
      "       2.419999, 2.078648, 2.237646, 2.073871, 1.697372, 2.085312,\n",
      "       1.431316, 1.855865, 1.838725, 1.502847, 1.386911, 2.539702,\n",
      "       2.250318, 2.699614, 1.962541, 1.462936, 2.243822, 0.535551,\n",
      "       2.052821, 1.904891, 1.924109, 2.584028, 1.376695, 0.789463,\n",
      "       2.560538, 1.778239, 1.801168, 0.952802, 1.117003, 1.781188,\n",
      "       1.002689, 2.00098 , 1.041688, 2.665764, 1.945364, 1.252723,\n",
      "       1.70798 , 2.125263, 2.1003  , 2.409154, 2.374433, 1.071791,\n",
      "       1.385475, 2.445202, 1.550953, 1.960151, 2.620628, 1.713357,\n",
      "       1.022162, 1.067337, 1.698138, 2.001137, 1.672983, 0.900969,\n",
      "       1.65972 , 1.392194, 1.301803, 1.666855, 3.468003, 0.820257,\n",
      "       1.66819 , 1.130072, 1.943092, 1.915641, 1.774768, 2.067105,\n",
      "       1.067635, 1.506847, 2.118687, 1.432958, 1.746974, 2.234938,\n",
      "       1.017468, 1.880618, 1.224303, 1.340068, 2.667867, 2.507652,\n",
      "       1.507785]),)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 667, in fit\n",
      "    Y = labelbin.fit_transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 324, in fit_transform\n",
      "    return self.fit(y).transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 301, in fit\n",
      "    self.classes_ = unique_labels(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 101, in unique_labels\n",
      "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
      "ValueError: Unknown label type: (array([ 2.03716 ,  0.163038,  1.281297,  1.75487 ,  0.899152,  2.873985,\n",
      "        2.063466,  1.641708,  1.681155,  1.008498,  2.00859 ,  2.069593,\n",
      "        1.257558,  2.403569,  2.065888,  1.697092,  2.066208,  2.334506,\n",
      "        1.878594,  1.918101,  1.32222 ,  2.185029,  2.358581,  1.941173,\n",
      "        1.363718,  2.300394,  2.166609,  0.760122,  1.11421 ,  1.185565,\n",
      "        1.82109 ,  0.97603 ,  1.033672,  1.776699,  1.52138 ,  1.569112,\n",
      "        2.349911,  2.37475 ,  1.259821,  1.534706,  1.118819,  1.561411,\n",
      "        1.9349  ,  1.5788  ,  0.980418,  2.329825,  1.825435,  2.916244,\n",
      "        2.049976,  1.670072,  1.117681,  1.515848,  1.576656,  1.913779,\n",
      "        0.90638 ,  2.261804,  1.926829,  2.703565,  0.191738,  1.369578,\n",
      "        1.946866,  0.493437,  1.309338,  1.521604,  2.529736,  2.435505,\n",
      "        2.112233,  1.706145,  2.240627,  1.635215,  1.970481,  2.61666 ,\n",
      "        1.3327  ,  1.497519,  2.046647,  2.227846,  1.835204,  1.500811,\n",
      "        1.958153,  0.97536 ,  1.454806,  1.275982,  2.43297 ,  1.496289,\n",
      "        1.919519,  1.625344,  1.940156,  1.636232,  1.572476,  1.034744,\n",
      "        0.32983 ,  0.850997,  2.136364,  1.418559,  1.908576,  0.659024,\n",
      "        0.943949,  1.812999,  2.163561,  0.63267 ,  2.024609,  1.018783,\n",
      "        0.989734,  1.850331,  0.684279,  2.312619,  0.827751,  0.538632,\n",
      "        1.052897,  0.289061,  1.523284,  0.600617,  1.595451,  2.337256,\n",
      "        2.43986 ,  2.646499,  1.327861,  1.304352,  1.981126,  1.126918,\n",
      "        2.477158,  2.497154,  1.227564,  1.019767,  1.807693,  1.993607,\n",
      "        0.693808,  2.120061,  1.388073,  1.300283,  1.773946,  0.735255,\n",
      "        1.396992,  2.039208,  0.545693,  2.601184,  0.917574,  1.927231,\n",
      "        1.526764,  1.750901,  2.175883,  1.439402,  2.946012,  0.334413,\n",
      "        2.006773,  1.002989,  2.036271,  1.658998,  1.477642,  1.638622,\n",
      "        1.229398,  1.123619,  2.073003,  1.205349,  0.615066,  2.350868,\n",
      "        2.729505,  1.591389,  0.538881,  1.933134,  1.800501,  2.174924,\n",
      "        1.994149,  1.732324,  1.22614 ,  0.689976,  0.938858,  1.717564,\n",
      "        0.932902,  0.289973,  0.914739,  1.404664,  3.196087,  1.536225,\n",
      "        0.597421,  1.623288,  1.34925 ,  0.889211, -0.443957,  1.640724,\n",
      "        2.152459,  1.066205,  2.073372,  1.251505, -0.154632,  2.009931,\n",
      "        1.379951,  1.487149,  3.171676,  1.307823,  1.317858,  1.850503,\n",
      "        1.243308,  1.207273,  0.427459,  1.901207,  1.328667,  1.252132,\n",
      "        2.28458 ,  1.278584,  2.551586,  0.738186,  2.09616 ,  1.341293,\n",
      "        2.459356,  1.799596,  1.751104,  1.81114 ,  1.784472,  2.119735,\n",
      "        2.421237,  1.608835,  0.306131,  0.576   ,  1.494694,  2.116776,\n",
      "        2.273904,  2.712332,  1.076953,  0.589   ,  2.383639, -0.604609,\n",
      "        1.990152,  1.521183,  1.829104,  1.828428,  1.934537,  1.823401,\n",
      "        1.80986 ,  0.406858,  1.393505,  1.45706 ,  0.521478,  0.630303,\n",
      "        0.561558,  2.078648,  2.237646,  2.073871,  1.697372,  2.085312,\n",
      "        1.431316,  1.855865,  1.838725,  1.502847,  1.386911,  2.539702,\n",
      "        2.250318,  2.699614,  1.962541,  1.462936,  2.243822,  0.535551,\n",
      "        2.052821,  1.904891,  1.924109,  2.584028,  1.376695,  0.789463,\n",
      "        2.560538,  1.778239,  1.801168,  0.952802,  1.117003,  1.781188,\n",
      "        1.002689,  2.00098 ,  1.041688,  2.665764,  1.945364,  1.252723,\n",
      "        1.70798 ,  2.125263,  2.1003  ,  2.409154,  2.374433,  1.071791,\n",
      "        1.385475,  2.445202,  1.550953,  1.960151,  2.620628,  1.713357,\n",
      "        1.022162,  1.067337,  1.698138,  2.001137,  1.672983,  0.900969,\n",
      "        1.65972 ,  1.392194,  1.301803,  1.666855,  3.468003,  0.820257,\n",
      "        1.66819 ,  1.130072,  1.943092,  1.915641,  1.774768,  2.067105,\n",
      "        1.067635,  1.506847,  2.118687,  1.432958,  1.746974,  2.234938,\n",
      "        1.017468,  1.880618,  1.224303,  1.340068,  2.667867,  2.507652,\n",
      "        1.507785]),)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 667, in fit\n",
      "    Y = labelbin.fit_transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 324, in fit_transform\n",
      "    return self.fit(y).transform(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py\", line 301, in fit\n",
      "    self.classes_ = unique_labels(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 101, in unique_labels\n",
      "    raise ValueError(\"Unknown label type: %s\" % repr(ys))\n",
      "ValueError: Unknown label type: (array([ 2.03716 ,  0.163038,  1.281297,  1.75487 ,  0.899152,  2.873985,\n",
      "        2.063466,  1.641708,  1.681155,  1.008498,  2.00859 ,  2.069593,\n",
      "        1.257558,  2.403569,  2.065888,  1.697092,  2.066208,  2.334506,\n",
      "        1.878594,  1.918101,  1.32222 ,  2.185029,  2.358581,  1.941173,\n",
      "        1.363718,  2.300394,  2.166609,  0.760122,  1.11421 ,  1.185565,\n",
      "        1.82109 ,  0.97603 ,  1.033672,  1.776699,  1.52138 ,  1.569112,\n",
      "        2.349911,  2.37475 ,  1.259821,  1.534706,  1.118819,  1.561411,\n",
      "        1.9349  ,  1.5788  ,  0.980418,  2.329825,  1.825435,  2.916244,\n",
      "        2.049976,  1.670072,  1.117681,  1.515848,  1.576656,  1.913779,\n",
      "        0.90638 ,  2.261804,  1.926829,  2.703565,  0.191738,  1.369578,\n",
      "        1.946866,  0.493437,  1.309338,  1.521604,  2.529736,  2.435505,\n",
      "        2.112233,  1.706145,  2.240627,  1.635215,  1.970481,  2.61666 ,\n",
      "        1.3327  ,  1.497519,  2.046647,  2.227846,  1.835204,  1.500811,\n",
      "        1.958153,  0.97536 ,  1.454806,  1.275982,  2.43297 ,  1.496289,\n",
      "        1.919519,  1.625344,  1.940156,  1.636232,  1.572476,  1.034744,\n",
      "        0.32983 ,  0.850997,  2.136364,  1.418559,  1.908576,  0.659024,\n",
      "        0.943949,  1.812999,  2.163561,  0.63267 ,  2.024609,  1.018783,\n",
      "        0.989734,  1.850331,  0.684279,  2.312619,  0.827751,  0.538632,\n",
      "        1.052897,  0.289061,  1.523284,  0.600617,  1.595451,  2.337256,\n",
      "        2.43986 ,  2.646499,  1.327861,  1.304352,  1.981126,  1.126918,\n",
      "        2.477158,  2.497154,  1.227564,  1.019767,  1.807693,  1.993607,\n",
      "        0.693808,  2.120061,  1.388073,  1.300283,  1.773946,  0.735255,\n",
      "        1.396992,  2.039208,  0.545693,  2.601184,  0.917574,  1.927231,\n",
      "        1.526764,  1.750901,  2.175883,  1.439402,  2.946012,  0.334413,\n",
      "        2.006773,  1.002989,  2.036271,  1.658998,  1.477642,  1.638622,\n",
      "        1.229398,  1.123619,  2.073003,  1.205349,  0.615066,  2.350868,\n",
      "        2.729505,  1.591389,  0.538881,  1.933134,  1.800501,  2.174924,\n",
      "        1.994149,  1.732324,  1.22614 ,  0.689976,  0.938858,  1.717564,\n",
      "        0.932902,  0.289973,  0.914739,  1.404664,  3.196087,  1.536225,\n",
      "        0.597421,  1.623288,  1.34925 ,  0.889211, -0.443957,  1.640724,\n",
      "        2.152459,  1.066205,  2.073372,  1.251505, -0.154632,  2.009931,\n",
      "        1.379951,  1.487149,  3.171676,  1.307823,  1.317858,  1.850503,\n",
      "        1.243308,  1.207273,  0.427459,  1.901207,  1.328667,  1.252132,\n",
      "        2.28458 ,  1.278584,  2.551586,  0.738186,  2.09616 ,  1.341293,\n",
      "        2.459356,  1.799596,  1.751104,  1.81114 ,  1.784472,  2.119735,\n",
      "        2.421237,  1.608835,  0.306131,  0.576   ,  1.494694,  2.116776,\n",
      "        2.273904,  2.712332,  1.076953,  0.589   ,  2.383639, -0.604609,\n",
      "        1.990152,  1.521183,  1.829104,  1.828428,  1.934537,  1.823401,\n",
      "        1.80986 ,  0.406858,  1.393505,  1.45706 ,  0.521478,  0.630303,\n",
      "        0.561558,  0.874383,  2.320437,  2.389362,  2.171778,  2.449553,\n",
      "        1.301573,  1.873835,  2.232851,  2.598119,  0.532722,  2.133964,\n",
      "        0.882511,  1.759203,  2.507832,  4.38237 ,  1.591212,  1.759308,\n",
      "        2.062261,  1.044671,  1.268465,  1.845302,  1.731031,  2.162984,\n",
      "        2.457407,  1.21513 ,  1.635316,  1.799942,  1.497437,  1.608918,\n",
      "        1.644011,  1.75933 ,  1.878956,  2.078355,  2.660737,  1.822076,\n",
      "        1.963631,  1.733528,  2.182249,  1.754007,  1.59271 ,  2.347214,\n",
      "        1.950402,  2.338371,  1.659106,  1.636299,  1.950205,  1.695195,\n",
      "        1.288635,  1.947221,  2.243745,  2.075306,  1.663446,  1.227539,\n",
      "        0.8751  ,  1.61698 ,  2.495399,  2.369219,  1.510265,  2.360308,\n",
      "        1.672772,  1.485888,  1.282133,  1.147457,  1.11794 ,  1.485829,\n",
      "        2.572892,  2.837846,  1.516674,  1.381426,  2.494787,  2.017904,\n",
      "        1.793095,  2.749407,  2.712948,  1.551902,  1.79027 ,  1.80543 ,\n",
      "        2.419999]),)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\tree\\_classes.py\", line 203, in fit\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 197, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py\", line 161, in fit\n",
      "    classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py\", line 367, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py\", line 734, in _validate_y_class_weight\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py\", line 197, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\marc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([ 2.03716 ,  0.163038,  1.281297,  1.75487 ,  0.899152,  2.873985,\n        2.063466,  1.641708,  1.681155,  1.008498,  2.00859 ,  2.069593,\n        1.257558,  2.403569,  2.065888,  1.697092,  2.066208,  2.334506,\n        1.878594,  1.918101,  1.32222 ,  2.185029,  2.358581,  1.941173,\n        1.363718,  2.300394,  2.166609,  0.760122,  1.11421 ,  1.185565,\n        1.82109 ,  0.97603 ,  1.033672,  1.776699,  1.52138 ,  1.569112,\n        2.349911,  2.37475 ,  1.259821,  1.534706,  1.118819,  1.561411,\n        1.9349  ,  1.5788  ,  0.980418,  2.329825,  1.825435,  2.916244,\n        2.049976,  1.670072,  1.117681,  1.515848,  1.576656,  1.913779,\n        0.90638 ,  2.261804,  1.926829,  2.703565,  0.191738,  1.369578,\n        1.946866,  0.493437,  1.309338,  1.521604,  2.529736,  2.435505,\n        2.112233,  1.706145,  2.240627,  1.635215,  1.970481,  2.61666 ,\n        1.3327  ,  1.497519,  2.046647,  2.227846,  1.835204,  1.500811,\n        1.958153,  0.97536 ,  1.454806,  1.275982,  2.43297 ,  1.496289,\n        1.919519,  1.625344,  1.940156,  1.636232,  1.572476,  1.034744,\n        0.32983 ,  0.850997,  2.136364,  1.418559,  1.908576,  0.659024,\n        0.943949,  1.812999,  2.163561,  0.63267 ,  2.024609,  1.018783,\n        0.989734,  1.850331,  0.684279,  2.312619,  0.827751,  0.538632,\n        1.052897,  0.289061,  1.523284,  0.600617,  1.595451,  2.337256,\n        2.43986 ,  2.646499,  1.327861,  1.304352,  1.981126,  1.126918,\n        2.477158,  2.497154,  1.227564,  1.019767,  1.807693,  1.993607,\n        0.693808,  2.120061,  1.388073,  1.300283,  1.773946,  0.735255,\n        1.396992,  2.039208,  0.545693,  2.601184,  0.917574,  1.927231,\n        1.526764,  1.750901,  2.175883,  1.439402,  2.946012,  0.334413,\n        2.006773,  1.002989,  2.036271,  1.658998,  1.477642,  1.638622,\n        1.229398,  1.123619,  2.073003,  1.205349,  0.615066,  2.350868,\n        2.729505,  1.591389,  0.538881,  1.933134,  1.800501,  2.174924,\n        1.994149,  1.732324,  1.22614 ,  0.689976,  0.938858,  1.717564,\n        0.932902,  0.289973,  0.914739,  1.404664,  3.196087,  1.536225,\n        0.597421,  1.623288,  1.34925 ,  0.889211, -0.443957,  1.640724,\n        2.152459,  1.066205,  2.073372,  1.251505, -0.154632,  2.009931,\n        1.379951,  1.487149,  3.171676,  1.307823,  1.317858,  1.850503,\n        1.243308,  1.207273,  0.427459,  1.901207,  1.328667,  1.252132,\n        2.28458 ,  1.278584,  2.551586,  0.738186,  2.09616 ,  1.341293,\n        2.459356,  1.799596,  1.751104,  1.81114 ,  1.784472,  2.119735,\n        2.421237,  1.608835,  0.306131,  0.576   ,  1.494694,  2.116776,\n        2.273904,  2.712332,  1.076953,  0.589   ,  2.383639, -0.604609,\n        1.990152,  1.521183,  1.829104,  1.828428,  1.934537,  1.823401,\n        1.80986 ,  0.406858,  1.393505,  1.45706 ,  0.521478,  0.630303,\n        0.561558,  0.874383,  2.320437,  2.389362,  2.171778,  2.449553,\n        1.301573,  1.873835,  2.232851,  2.598119,  0.532722,  2.133964,\n        0.882511,  1.759203,  2.507832,  4.38237 ,  1.591212,  1.759308,\n        2.062261,  1.044671,  1.268465,  1.845302,  1.731031,  2.162984,\n        2.457407,  1.21513 ,  1.635316,  1.799942,  1.497437,  1.608918,\n        1.644011,  1.75933 ,  1.878956,  2.078355,  2.660737,  1.822076,\n        1.963631,  1.733528,  2.182249,  1.754007,  1.59271 ,  2.347214,\n        1.950402,  2.338371,  1.659106,  1.636299,  1.950205,  1.695195,\n        1.288635,  1.947221,  2.243745,  2.075306,  1.663446,  1.227539,\n        0.8751  ,  1.61698 ,  2.495399,  2.369219,  1.510265,  2.360308,\n        1.672772,  1.485888,  1.282133,  1.147457,  1.11794 ,  1.485829,\n        2.572892,  2.837846,  1.516674,  1.381426,  2.494787,  2.017904,\n        1.793095,  2.749407,  2.712948,  1.551902,  1.79027 ,  1.80543 ,\n        2.419999,  2.078648,  2.237646,  2.073871,  1.697372,  2.085312,\n        1.431316,  1.855865,  1.838725,  1.502847,  1.386911,  2.539702,\n        2.250318,  2.699614,  1.962541,  1.462936,  2.243822,  0.535551,\n        2.052821,  1.904891,  1.924109,  2.584028,  1.376695,  0.789463,\n        2.560538,  1.778239,  1.801168,  0.952802,  1.117003,  1.781188,\n        1.002689,  2.00098 ,  1.041688,  2.665764,  1.945364,  1.252723,\n        1.70798 ,  2.125263,  2.1003  ,  2.409154,  2.374433,  1.071791,\n        1.385475,  2.445202,  1.550953,  1.960151,  2.620628,  1.713357,\n        1.022162,  1.067337,  1.698138,  2.001137,  1.672983,  0.900969,\n        1.65972 ,  1.392194,  1.301803,  1.666855,  3.468003,  0.820257,\n        1.66819 ,  1.130072,  1.943092,  1.915641,  1.774768,  2.067105,\n        1.067635,  1.506847,  2.118687,  1.432958,  1.746974,  2.234938,\n        1.017468,  1.880618,  1.224303,  1.340068,  2.667867,  2.507652,\n        1.507785]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marc\\Desktop\\Projetos\\filtroColorido\\labelrizator-am2\\emotions.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=13'>14</a>\u001b[0m grid_param \u001b[39m=\u001b[39m [ \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=14'>15</a>\u001b[0m     {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=15'>16</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m: [MultinomialNB()],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=29'>30</a>\u001b[0m     },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=30'>31</a>\u001b[0m ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=32'>33</a>\u001b[0m br \u001b[39m=\u001b[39m GridSearchCV(BinaryRelevance(), grid_param, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/marc/Desktop/Projetos/filtroColorido/labelrizator-am2/emotions.ipynb#ch0000008?line=34'>35</a>\u001b[0m br\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mvalues, Y_train\u001b[39m.\u001b[39;49mvalues)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/model_selection/_search.py?line=923'>924</a>\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/model_selection/_search.py?line=924'>925</a>\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/model_selection/_search.py?line=925'>926</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/model_selection/_search.py?line=926'>927</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/model_selection/_search.py?line=927'>928</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\skmultilearn\\problem_transform\\br.py:161\u001b[0m, in \u001b[0;36mBinaryRelevance.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/skmultilearn/problem_transform/br.py?line=158'>159</a>\u001b[0m     \u001b[39mif\u001b[39;00m issparse(y_subset) \u001b[39mand\u001b[39;00m y_subset\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m y_subset\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/skmultilearn/problem_transform/br.py?line=159'>160</a>\u001b[0m         y_subset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(y_subset\u001b[39m.\u001b[39mtoarray())\n\u001b[1;32m--> <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/skmultilearn/problem_transform/br.py?line=160'>161</a>\u001b[0m     classifier\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_input_format(\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/skmultilearn/problem_transform/br.py?line=161'>162</a>\u001b[0m         X), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_output_format(y_subset))\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/skmultilearn/problem_transform/br.py?line=162'>163</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifiers_\u001b[39m.\u001b[39mappend(classifier)\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/skmultilearn/problem_transform/br.py?line=164'>165</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\naive_bayes.py:667\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/naive_bayes.py?line=663'>664</a>\u001b[0m _, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/naive_bayes.py?line=665'>666</a>\u001b[0m labelbin \u001b[39m=\u001b[39m LabelBinarizer()\n\u001b[1;32m--> <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/naive_bayes.py?line=666'>667</a>\u001b[0m Y \u001b[39m=\u001b[39m labelbin\u001b[39m.\u001b[39;49mfit_transform(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/naive_bayes.py?line=667'>668</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m labelbin\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/naive_bayes.py?line=668'>669</a>\u001b[0m \u001b[39mif\u001b[39;00m Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py:324\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=303'>304</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=304'>305</a>\u001b[0m     \u001b[39m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=305'>306</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=306'>307</a>\u001b[0m \u001b[39m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=321'>322</a>\u001b[0m \u001b[39m        will be of CSR format.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=322'>323</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=323'>324</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(y)\u001b[39m.\u001b[39mtransform(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py:301\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=297'>298</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my has 0 samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y)\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=299'>300</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_input_ \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39missparse(y)\n\u001b[1;32m--> <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=300'>301</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m unique_labels(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/preprocessing/_label.py?line=301'>302</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py:101\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/utils/multiclass.py?line=98'>99</a>\u001b[0m _unique_labels \u001b[39m=\u001b[39m _FN_UNIQUE_LABELS\u001b[39m.\u001b[39mget(label_type, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/utils/multiclass.py?line=99'>100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/utils/multiclass.py?line=100'>101</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mrepr\u001b[39m(ys))\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/utils/multiclass.py?line=102'>103</a>\u001b[0m ys_labels \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(chain\u001b[39m.\u001b[39mfrom_iterable(_unique_labels(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m ys))\n\u001b[0;32m    <a href='file:///c%3A/Users/marc/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/sklearn/utils/multiclass.py?line=104'>105</a>\u001b[0m \u001b[39m# Check that we don't mix string type with number type\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([ 2.03716 ,  0.163038,  1.281297,  1.75487 ,  0.899152,  2.873985,\n        2.063466,  1.641708,  1.681155,  1.008498,  2.00859 ,  2.069593,\n        1.257558,  2.403569,  2.065888,  1.697092,  2.066208,  2.334506,\n        1.878594,  1.918101,  1.32222 ,  2.185029,  2.358581,  1.941173,\n        1.363718,  2.300394,  2.166609,  0.760122,  1.11421 ,  1.185565,\n        1.82109 ,  0.97603 ,  1.033672,  1.776699,  1.52138 ,  1.569112,\n        2.349911,  2.37475 ,  1.259821,  1.534706,  1.118819,  1.561411,\n        1.9349  ,  1.5788  ,  0.980418,  2.329825,  1.825435,  2.916244,\n        2.049976,  1.670072,  1.117681,  1.515848,  1.576656,  1.913779,\n        0.90638 ,  2.261804,  1.926829,  2.703565,  0.191738,  1.369578,\n        1.946866,  0.493437,  1.309338,  1.521604,  2.529736,  2.435505,\n        2.112233,  1.706145,  2.240627,  1.635215,  1.970481,  2.61666 ,\n        1.3327  ,  1.497519,  2.046647,  2.227846,  1.835204,  1.500811,\n        1.958153,  0.97536 ,  1.454806,  1.275982,  2.43297 ,  1.496289,\n        1.919519,  1.625344,  1.940156,  1.636232,  1.572476,  1.034744,\n        0.32983 ,  0.850997,  2.136364,  1.418559,  1.908576,  0.659024,\n        0.943949,  1.812999,  2.163561,  0.63267 ,  2.024609,  1.018783,\n        0.989734,  1.850331,  0.684279,  2.312619,  0.827751,  0.538632,\n        1.052897,  0.289061,  1.523284,  0.600617,  1.595451,  2.337256,\n        2.43986 ,  2.646499,  1.327861,  1.304352,  1.981126,  1.126918,\n        2.477158,  2.497154,  1.227564,  1.019767,  1.807693,  1.993607,\n        0.693808,  2.120061,  1.388073,  1.300283,  1.773946,  0.735255,\n        1.396992,  2.039208,  0.545693,  2.601184,  0.917574,  1.927231,\n        1.526764,  1.750901,  2.175883,  1.439402,  2.946012,  0.334413,\n        2.006773,  1.002989,  2.036271,  1.658998,  1.477642,  1.638622,\n        1.229398,  1.123619,  2.073003,  1.205349,  0.615066,  2.350868,\n        2.729505,  1.591389,  0.538881,  1.933134,  1.800501,  2.174924,\n        1.994149,  1.732324,  1.22614 ,  0.689976,  0.938858,  1.717564,\n        0.932902,  0.289973,  0.914739,  1.404664,  3.196087,  1.536225,\n        0.597421,  1.623288,  1.34925 ,  0.889211, -0.443957,  1.640724,\n        2.152459,  1.066205,  2.073372,  1.251505, -0.154632,  2.009931,\n        1.379951,  1.487149,  3.171676,  1.307823,  1.317858,  1.850503,\n        1.243308,  1.207273,  0.427459,  1.901207,  1.328667,  1.252132,\n        2.28458 ,  1.278584,  2.551586,  0.738186,  2.09616 ,  1.341293,\n        2.459356,  1.799596,  1.751104,  1.81114 ,  1.784472,  2.119735,\n        2.421237,  1.608835,  0.306131,  0.576   ,  1.494694,  2.116776,\n        2.273904,  2.712332,  1.076953,  0.589   ,  2.383639, -0.604609,\n        1.990152,  1.521183,  1.829104,  1.828428,  1.934537,  1.823401,\n        1.80986 ,  0.406858,  1.393505,  1.45706 ,  0.521478,  0.630303,\n        0.561558,  0.874383,  2.320437,  2.389362,  2.171778,  2.449553,\n        1.301573,  1.873835,  2.232851,  2.598119,  0.532722,  2.133964,\n        0.882511,  1.759203,  2.507832,  4.38237 ,  1.591212,  1.759308,\n        2.062261,  1.044671,  1.268465,  1.845302,  1.731031,  2.162984,\n        2.457407,  1.21513 ,  1.635316,  1.799942,  1.497437,  1.608918,\n        1.644011,  1.75933 ,  1.878956,  2.078355,  2.660737,  1.822076,\n        1.963631,  1.733528,  2.182249,  1.754007,  1.59271 ,  2.347214,\n        1.950402,  2.338371,  1.659106,  1.636299,  1.950205,  1.695195,\n        1.288635,  1.947221,  2.243745,  2.075306,  1.663446,  1.227539,\n        0.8751  ,  1.61698 ,  2.495399,  2.369219,  1.510265,  2.360308,\n        1.672772,  1.485888,  1.282133,  1.147457,  1.11794 ,  1.485829,\n        2.572892,  2.837846,  1.516674,  1.381426,  2.494787,  2.017904,\n        1.793095,  2.749407,  2.712948,  1.551902,  1.79027 ,  1.80543 ,\n        2.419999,  2.078648,  2.237646,  2.073871,  1.697372,  2.085312,\n        1.431316,  1.855865,  1.838725,  1.502847,  1.386911,  2.539702,\n        2.250318,  2.699614,  1.962541,  1.462936,  2.243822,  0.535551,\n        2.052821,  1.904891,  1.924109,  2.584028,  1.376695,  0.789463,\n        2.560538,  1.778239,  1.801168,  0.952802,  1.117003,  1.781188,\n        1.002689,  2.00098 ,  1.041688,  2.665764,  1.945364,  1.252723,\n        1.70798 ,  2.125263,  2.1003  ,  2.409154,  2.374433,  1.071791,\n        1.385475,  2.445202,  1.550953,  1.960151,  2.620628,  1.713357,\n        1.022162,  1.067337,  1.698138,  2.001137,  1.672983,  0.900969,\n        1.65972 ,  1.392194,  1.301803,  1.666855,  3.468003,  0.820257,\n        1.66819 ,  1.130072,  1.943092,  1.915641,  1.774768,  2.067105,\n        1.067635,  1.506847,  2.118687,  1.432958,  1.746974,  2.234938,\n        1.017468,  1.880618,  1.224303,  1.340068,  2.667867,  2.507652,\n        1.507785]),)"
     ]
    }
   ],
   "source": [
    "# Começamos com o Binary Relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Realizamos uma Cross Validation para determinarmos os melhores\n",
    "# parâmetros de execução do algoritmo de classificação multirrótulo.\n",
    "# Dentre esses parâmetros, está o classificador que vamos utilizar\n",
    "# para resolver o problema após conversão para um rótulo.\n",
    "\n",
    "\n",
    "grid_param = [ \n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [10, 50, 100],\n",
    "        'classifier__random_state': [42],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__bootstrap': [True, False],\n",
    "        'classifier__random_state': [42],\n",
    "    },\n",
    "]\n",
    "\n",
    "br = GridSearchCV(BinaryRelevance(), grid_param, scoring='accuracy')\n",
    "\n",
    "br.fit(X_train.values, Y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762739597942964"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valor de acurácia da melhor escolha do Cross Validation\n",
    "br.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': RandomForestClassifier(random_state=42),\n",
       " 'classifier__bootstrap': True,\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__random_state': 42}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhores parâmetros escolhidos pelo Cross Validation\n",
    "br.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=RandomForestClassifier(random_state=42),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhores parâmetros escolhidos pelo Cross Validation\n",
    "# De forma simplificada\n",
    "br.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=RandomForestClassifier(random_state=42),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza o fit com os parâmetros escolhidos \n",
    "br = br.best_estimator_\n",
    "br.fit(X_train.values, Y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698492462311558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testa a qualidade da solução\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Verificar acurácia\n",
    "pred = br.predict(X_test.values)\n",
    "accuracy_score(Y_test.values, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013028103480364787"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o Hamming Loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "hamming_loss(Y_test.values, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ClassifierChain(require_dense=[True, True]),\n",
       "             param_grid=[{'classifier': [MultinomialNB()],\n",
       "                          'classifier__alpha': [0.7, 1.0]},\n",
       "                         {'classifier': [DecisionTreeClassifier(max_depth=10,\n",
       "                                                                random_state=42)],\n",
       "                          'classifier__criterion': ['gini', 'entropy'],\n",
       "                          'classifier__max_depth': [10, 50, 100],\n",
       "                          'classifier__random_state': [42]},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__bootstrap': [True, False],\n",
       "                          'classifier__criterion': ['gini', 'entropy'],\n",
       "                          'classifier__random_state': [42]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos utilizar o Classifier Chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "# Realizamos uma Cross Validation para determinarmos os melhores\n",
    "# parâmetros de execução do algoritmo de classificação multirrótulo.\n",
    "# Dentre esses parâmetros, está o classificador que vamos utilizar\n",
    "# para resolver o problema após conversão para um rótulo.\n",
    "\n",
    "grid_param = [ \n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [10, 50, 100],\n",
    "        'classifier__random_state': [42],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__bootstrap': [True, False],\n",
    "        'classifier__random_state': [42],\n",
    "    },\n",
    "]\n",
    "\n",
    "cc = GridSearchCV(ClassifierChain(), grid_param, scoring='accuracy')\n",
    "cc.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762038335670875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__max_depth': 10,\n",
       " 'classifier__random_state': 42}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=DecisionTreeClassifier(max_depth=10,\n",
       "                                                  random_state=42),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=DecisionTreeClassifier(max_depth=10,\n",
       "                                                  random_state=42),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza o fit com os parâmetros escolhidos \n",
    "cc = cc.best_estimator_\n",
    "cc.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698492462311558"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar acurácia\n",
    "pred2 = cc.predict(X_test.values)\n",
    "accuracy_score(Y_test.values, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011166945840312675"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o Hamming Loss\n",
    "hamming_loss(Y_test.values, pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LabelPowerset(require_dense=[True, True]),\n",
       "             param_grid=[{'classifier': [MultinomialNB()],\n",
       "                          'classifier__alpha': [0.7, 1.0]},\n",
       "                         {'classifier': [DecisionTreeClassifier(max_depth=50,\n",
       "                                                                random_state=42)],\n",
       "                          'classifier__criterion': ['gini', 'entropy'],\n",
       "                          'classifier__max_depth': [10, 50, 100],\n",
       "                          'classifier__random_state': [42]},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__bootstrap': [True, False],\n",
       "                          'classifier__criterion': ['gini', 'entropy'],\n",
       "                          'classifier__random_state': [42]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos utilizar o Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "# Realizamos uma Cross Validation para determinarmos os melhores\n",
    "# parâmetros de execução do algoritmo de classificação multirrótulo.\n",
    "# Dentre esses parâmetros, está o classificador que vamos utilizar\n",
    "# para resolver o problema após conversão para um rótulo.\n",
    "\n",
    "grid_param = [ \n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [10, 50, 100],\n",
    "        'classifier__random_state': [42],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__bootstrap': [True, False],\n",
    "        'classifier__random_state': [42],\n",
    "    },\n",
    "]\n",
    "\n",
    "lp = GridSearchCV(LabelPowerset(), grid_param, scoring='accuracy')\n",
    "lp.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741000467508181"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': DecisionTreeClassifier(max_depth=50, random_state=42),\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__max_depth': 50,\n",
       " 'classifier__random_state': 42}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=DecisionTreeClassifier(max_depth=50, random_state=42),\n",
       "              require_dense=[True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=DecisionTreeClassifier(max_depth=50, random_state=42),\n",
       "              require_dense=[True, True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza o fit com os parâmetros escolhidos \n",
    "lp = lp.best_estimator_\n",
    "lp.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698492462311558"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar acurácia\n",
    "pred3 = lp.predict(X_test.values)\n",
    "accuracy_score(Y_test.values, pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011166945840312675"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o Hamming Loss\n",
    "hamming_loss(Y_test.values, pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Agora iremos mostrar os resultados experimentais obtidos por cada algoritmo de classificação multirrótulo. \n",
    "Além disso, vamos plotar gráficos para comparar os valores de acurácia e *Hamming Loss* dos métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Experimentais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  17  18  19  20  21  22  23  \\\n",
       "0     0   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2     0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3     0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4     0   0   1   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "194   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "195   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "196   0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "197   0   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "198   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "     24  25  26  \n",
       "0     0   0   0  \n",
       "1     0   0   0  \n",
       "2     0   0   0  \n",
       "3     0   0   0  \n",
       "4     0   0   0  \n",
       "..   ..  ..  ..  \n",
       "194   0   0   0  \n",
       "195   0   0   0  \n",
       "196   0   0   0  \n",
       "197   0   0   0  \n",
       "198   0   0   0  \n",
       "\n",
       "[199 rows x 27 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado predito pelo algoritmo Binary Relevance\n",
    "pd.DataFrame.sparse.from_spmatrix(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  17  18  19  20  21  22  23  \\\n",
       "0     0   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2     0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3     0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4     0   0   1   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "194   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "195   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "196   0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "197   0   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "198   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "     24  25  26  \n",
       "0     0   0   0  \n",
       "1     0   0   0  \n",
       "2     0   0   0  \n",
       "3     0   0   0  \n",
       "4     0   0   0  \n",
       "..   ..  ..  ..  \n",
       "194   0   0   0  \n",
       "195   0   0   0  \n",
       "196   0   0   0  \n",
       "197   0   0   0  \n",
       "198   0   0   0  \n",
       "\n",
       "[199 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado predito pelo algoritmo Classifier Chains\n",
    "pd.DataFrame.sparse.from_spmatrix(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  17  18  19  20  21  22  23  \\\n",
       "0     0   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2     0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3     0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4     0   0   1   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "194   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "195   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "196   0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "197   0   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "198   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "     24  25  26  \n",
       "0     0   0   0  \n",
       "1     0   0   0  \n",
       "2     0   0   0  \n",
       "3     0   0   0  \n",
       "4     0   0   0  \n",
       "..   ..  ..  ..  \n",
       "194   0   0   0  \n",
       "195   0   0   0  \n",
       "196   0   0   0  \n",
       "197   0   0   0  \n",
       "198   0   0   0  \n",
       "\n",
       "[199 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado predito pelo algoritmo Label Powerset\n",
    "pd.DataFrame.sparse.from_spmatrix(pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDOC00154</th>\n",
       "      <th>PDOC00343</th>\n",
       "      <th>PDOC00271</th>\n",
       "      <th>PDOC00064</th>\n",
       "      <th>PDOC00791</th>\n",
       "      <th>PDOC00380</th>\n",
       "      <th>PDOC50007</th>\n",
       "      <th>PDOC00224</th>\n",
       "      <th>PDOC00100</th>\n",
       "      <th>PDOC00670</th>\n",
       "      <th>...</th>\n",
       "      <th>PDOC00662</th>\n",
       "      <th>PDOC00018</th>\n",
       "      <th>PDOC50001</th>\n",
       "      <th>PDOC00014</th>\n",
       "      <th>PDOC00750</th>\n",
       "      <th>PDOC50196</th>\n",
       "      <th>PDOC50199</th>\n",
       "      <th>PDOC00660</th>\n",
       "      <th>PDOC00653</th>\n",
       "      <th>PDOC00030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PDOC00154  PDOC00343  PDOC00271  PDOC00064  PDOC00791  PDOC00380  \\\n",
       "0            0          0          0          1          0          0   \n",
       "1            1          0          0          0          0          0   \n",
       "2            0          0          0          0          1          0   \n",
       "3            0          0          0          0          1          0   \n",
       "4            0          0          1          0          0          0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "194          0          0          0          0          1          0   \n",
       "195          0          0          0          0          1          0   \n",
       "196          0          0          0          0          0          0   \n",
       "197          0          0          0          1          0          0   \n",
       "198          0          1          0          0          0          0   \n",
       "\n",
       "     PDOC50007  PDOC00224  PDOC00100  PDOC00670  ...  PDOC00662  PDOC00018  \\\n",
       "0            0          0          0          0  ...          0          0   \n",
       "1            0          0          0          0  ...          0          0   \n",
       "2            0          0          0          0  ...          0          0   \n",
       "3            0          0          0          0  ...          0          0   \n",
       "4            0          0          0          0  ...          0          0   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "194          0          0          0          0  ...          0          0   \n",
       "195          0          0          0          0  ...          0          0   \n",
       "196          1          0          0          0  ...          0          0   \n",
       "197          0          0          0          0  ...          0          0   \n",
       "198          0          0          0          0  ...          0          0   \n",
       "\n",
       "     PDOC50001  PDOC00014  PDOC00750  PDOC50196  PDOC50199  PDOC00660  \\\n",
       "0            0          0          0          0          0          0   \n",
       "1            0          0          0          0          0          0   \n",
       "2            0          0          0          0          0          0   \n",
       "3            0          0          0          0          0          0   \n",
       "4            0          0          0          0          0          0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "194          0          0          0          0          0          0   \n",
       "195          0          0          0          0          0          0   \n",
       "196          0          0          0          0          0          0   \n",
       "197          0          0          0          0          0          0   \n",
       "198          0          0          0          0          0          0   \n",
       "\n",
       "     PDOC00653  PDOC00030  \n",
       "0            0          0  \n",
       "1            0          0  \n",
       "2            0          0  \n",
       "3            0          0  \n",
       "4            0          0  \n",
       "..         ...        ...  \n",
       "194          0          0  \n",
       "195          0          0  \n",
       "196          0          0  \n",
       "197          0          0  \n",
       "198          0          0  \n",
       "\n",
       "[199 rows x 27 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores de rotulos apresentados pelo conjunto de treino\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos\n",
    "Vamos plotar o gráfico de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot das acurácias dos métodos multirrótulos.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Vamos plotar um gráfico de barras\n",
    "\n",
    "# Eixo X\n",
    "algorithms = ['BR', 'CC', 'LP']\n",
    "# Eixo Y\n",
    "val_acc = [accuracy_score(Y_test.values, pred), accuracy_score(Y_test.values, pred2), accuracy_score(Y_test.values, pred3)]\n",
    "\n",
    "# Barras do gráfico\n",
    "plt.bar(algorithms, val_acc, color=\"gray\")\n",
    "\n",
    "# Nome das barras\n",
    "plt.xticks(algorithms)\n",
    "\n",
    "# Informação do eixo y\n",
    "plt.ylabel('Acurácia')\n",
    "\n",
    "# Informação do eixo X\n",
    "plt.xlabel('Algoritmos')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot do gráfico de *Hamming Loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot dos Hamming Loss dos métodos multirrótulos.\n",
    "# Vamos plotar um gráfico de barras\n",
    "\n",
    "# Eixo X\n",
    "algorithms = ['BR', 'CC', 'LP']\n",
    "# Eixo Y\n",
    "val_acc = [hamming_loss(Y_test.values, pred), hamming_loss(Y_test.values, pred2), hamming_loss(Y_test.values, pred3)]\n",
    "\n",
    "# Barras do gráfico\n",
    "plt.bar(algorithms, val_acc, color=\"gray\")\n",
    "\n",
    "# Nome das barras\n",
    "plt.xticks(algorithms)\n",
    "\n",
    "# Informação do eixo y\n",
    "plt.ylabel('Acurácia')\n",
    "\n",
    "# Informação do eixo X\n",
    "plt.xlabel('Algoritmos')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método vencedor é ? \n",
    "\n",
    "**TERMINEM DE DESCOBRIR AE QM É O MELHOR MÉTODO E ARRUMEM O GRÁFICO DE ACURÁCIA, SE VCS ACHAREM Q TEM Q ARRUMAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Tem conclusão?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
